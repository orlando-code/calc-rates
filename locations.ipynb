{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "# general\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extractor</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Secondary_check</th>\n",
       "      <th>Include</th>\n",
       "      <th>Authors</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Year</th>\n",
       "      <th>Species_types</th>\n",
       "      <th>Taxa</th>\n",
       "      <th>Location</th>\n",
       "      <th>...</th>\n",
       "      <th>Salinity_sd_ppt</th>\n",
       "      <th>n</th>\n",
       "      <th>Calcification</th>\n",
       "      <th>Calcification_se</th>\n",
       "      <th>Calcification_sd</th>\n",
       "      <th>Calcification_units</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Methods</th>\n",
       "      <th>Notes+</th>\n",
       "      <th>Notes++</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orlando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>Bergstrom E.; Lahnstein J.; Collins H.; Page T...</td>\n",
       "      <td>10.1111/jpy.13290</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Porollithon cf onkodes</td>\n",
       "      <td>Algae</td>\n",
       "      <td>Lizard Island, GBR, Australia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.970803</td>\n",
       "      <td>0.25555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mg cm-2day-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orlando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>Bergstrom E.; Lahnstein J.; Collins H.; Page T...</td>\n",
       "      <td>10.1111/jpy.13290</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Porollithon cf onkodes</td>\n",
       "      <td>Algae</td>\n",
       "      <td>Lizard Island, GBR, Australia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2.408759</td>\n",
       "      <td>0.18976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mg cm-2day-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Orlando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>Bergstrom E.; Lahnstein J.; Collins H.; Page T...</td>\n",
       "      <td>10.1111/jpy.13290</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Porollithon cf onkodes</td>\n",
       "      <td>Algae</td>\n",
       "      <td>Lizard Island, GBR, Australia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.664234</td>\n",
       "      <td>0.167864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mg cm-2day-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Orlando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>Bergstrom E.; Lahnstein J.; Collins H.; Page T...</td>\n",
       "      <td>10.1111/jpy.13290</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Porollithon cf onkodes</td>\n",
       "      <td>Algae</td>\n",
       "      <td>Lizard Island, GBR, Australia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.839416</td>\n",
       "      <td>0.124074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mg cm-2day-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orlando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>Bergstrom E.; Lahnstein J.; Collins H.; Page T...</td>\n",
       "      <td>10.1111/jpy.13290</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Lithophyllum cf insipidum</td>\n",
       "      <td>Algae</td>\n",
       "      <td>Lizard Island, GBR, Australia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.467626</td>\n",
       "      <td>0.131372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mg cm-2day-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Extractor Notes  Secondary_check Include  \\\n",
       "0   Orlando   NaN                1     yes   \n",
       "1   Orlando   NaN                1     yes   \n",
       "2   Orlando   NaN                1     yes   \n",
       "3   Orlando   NaN                1     yes   \n",
       "4   Orlando   NaN                1     yes   \n",
       "\n",
       "                                             Authors                DOI  \\\n",
       "0  Bergstrom E.; Lahnstein J.; Collins H.; Page T...  10.1111/jpy.13290   \n",
       "1  Bergstrom E.; Lahnstein J.; Collins H.; Page T...  10.1111/jpy.13290   \n",
       "2  Bergstrom E.; Lahnstein J.; Collins H.; Page T...  10.1111/jpy.13290   \n",
       "3  Bergstrom E.; Lahnstein J.; Collins H.; Page T...  10.1111/jpy.13290   \n",
       "4  Bergstrom E.; Lahnstein J.; Collins H.; Page T...  10.1111/jpy.13290   \n",
       "\n",
       "        Year              Species_types   Taxa                       Location  \\\n",
       "0 2023-01-01     Porollithon cf onkodes  Algae  Lizard Island, GBR, Australia   \n",
       "1 2023-01-01     Porollithon cf onkodes  Algae  Lizard Island, GBR, Australia   \n",
       "2 2023-01-01     Porollithon cf onkodes  Algae  Lizard Island, GBR, Australia   \n",
       "3 2023-01-01     Porollithon cf onkodes  Algae  Lizard Island, GBR, Australia   \n",
       "4 2023-01-01  Lithophyllum cf insipidum  Algae  Lizard Island, GBR, Australia   \n",
       "\n",
       "   ... Salinity_sd_ppt  n Calcification Calcification_se  Calcification_sd  \\\n",
       "0  ...             NaN  5      1.970803          0.25555               NaN   \n",
       "1  ...             NaN  5      2.408759          0.18976               NaN   \n",
       "2  ...             NaN  5      1.664234         0.167864               NaN   \n",
       "3  ...             NaN  5      1.839416         0.124074               NaN   \n",
       "4  ...             NaN  5      1.467626         0.131372               NaN   \n",
       "\n",
       "  Calcification_units  Duration  Methods  Notes+  Notes++  \n",
       "0        mg cm-2day-1       NaN      NaN     NaN      NaN  \n",
       "1        mg cm-2day-1       NaN      NaN     NaN      NaN  \n",
       "2        mg cm-2day-1       NaN      NaN     NaN      NaN  \n",
       "3        mg cm-2day-1       NaN      NaN     NaN      NaN  \n",
       "4        mg cm-2day-1       NaN      NaN     NaN      NaN  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load data\n",
    "fp = \"data/Orlando_data.xlsx\"\n",
    "# algae data\n",
    "df = pd.read_excel(fp, sheet_name=\"all_data\")\n",
    "df = df[df.Include == 'yes']    # filter out data not matching criteria\n",
    "df['Year'] = pd.to_datetime(df['Year'], format='%Y')    # datetime format for later plotting\n",
    "df[['DOI', 'Year', 'Authors',]] = df[['DOI', 'Year', 'Authors']].ffill()\n",
    "df.columns = df.columns.str.replace(' ', '_')   # process columns to replace whitespace with underscore\n",
    "df.columns = df.columns.str.replace('[()]', '', regex=True) # remove '(' and ')' from column names\n",
    "# remove any rows in which 'n' has '~' in the string\n",
    "df = df[~df['n'].str.contains('~', na=False)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign value for each row to coords, or if no coords, location\n",
    "df['loc'] = df['Cleaned_Coords'].fillna(df['Location'])\n",
    "df['loc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_array = df['Cleaned_Coords'].dropna().unique()\n",
    "coords_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_dd(degrees, minutes=0, seconds=0, direction=\"\"):\n",
    "    \"\"\"Convert degrees, minutes, and seconds to decimal degrees.\"\"\"\n",
    "    decimal_degrees = float(degrees) + float(minutes) / 60 + float(seconds) / 3600\n",
    "    if direction in [\"S\", \"W\"]:\n",
    "        decimal_degrees *= -1\n",
    "    return decimal_degrees\n",
    "\n",
    "def parse_coordinates(coord):\n",
    "    \"\"\"Convert various coordinate formats to decimal degrees.\"\"\"\n",
    "    coord = coord.strip()\n",
    "    coord = coord.replace(\"''\", '\"')\n",
    "    coord = coord.replace('\"', \"+\")\n",
    "    coord = coord.replace(\"′\", \"'\")\n",
    "    coord = coord.replace(\"’\", \"'\")\n",
    "\n",
    "    # **Decimal Degrees (DD)**\n",
    "    dd_match = re.match(r\"(-?\\d+\\.\\d+)\\s*[\\u00B0]?\\s*,?\\s*(-?\\d+\\.\\d+)\\s*[\\u00B0]?\", coord)\n",
    "    if dd_match:\n",
    "        return float(dd_match.group(1)), float(dd_match.group(2))\n",
    "\n",
    "    # **Degrees and Decimal Minutes (DMM)**\n",
    "    dmm_match = re.match(\n",
    "        r\"(\\d+\\.?\\d*)\\u00B0\\s*([NS]),?\\s*(\\d+\\.?\\d*)\\u00B0\\s*([EW])\", coord\n",
    "    )\n",
    "    if dmm_match:\n",
    "        lat_dd = dms_to_dd(dmm_match.group(1), direction=dmm_match.group(2))\n",
    "        lon_dd = dms_to_dd(dmm_match.group(3), direction=dmm_match.group(4))\n",
    "        return lat_dd, lon_dd\n",
    "\n",
    "    # **Degrees, Minutes, and Seconds (DMS) & Degrees and Minutes (DM)**\n",
    "    dms_match = re.match(\n",
    "        r\"(\\d+)\\u00B0\\s*(\\d+)[′']\\s*([\\d.]*)?[\\″+]?\\s*([NSEW])\\D+\"\n",
    "        r\"(\\d+)\\u00B0\\s*(\\d+)[′']\\s*([\\d.]*)?[\\″+]?\\s*([EWNS])\", coord\n",
    "    )\n",
    "    if dms_match:\n",
    "        lat_dd = dms_to_dd(dms_match.group(1), dms_match.group(2), dms_match.group(3) or 0, dms_match.group(4))\n",
    "        lon_dd = dms_to_dd(dms_match.group(5), dms_match.group(6), dms_match.group(7) or 0, dms_match.group(8))\n",
    "        return lat_dd, lon_dd\n",
    "\n",
    "    raise ValueError(f\"Unknown coordinate format: {coord}\")\n",
    "\n",
    "correct = 0\n",
    "for coord in coords_array:\n",
    "    try:\n",
    "        lat, lon = parse_coordinates(coord)\n",
    "        print(f\"Original: {coord} → Decimal Degrees: ({lat}, {lon})\")\n",
    "        correct += 1\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        \n",
    "print('# CORRECT:', correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing coordinates with Google Maps API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in others\n",
    "denisa_df = pd.read_excel(\"data/Data extraction_Denisa.xlsx\", sheet_name=\"Data extraction\")\n",
    "ashtyn_df = pd.read_excel(\"data/DataExtraction_AI.xlsx\", sheet_name=\"Data_Extraction\")\n",
    "\n",
    "# concatenate data\n",
    "GOOGLE_MAPS_API_KEY = utils.read_yaml(\"api_keys.yaml\")['google_maps_api']\n",
    "\n",
    "gmaps_client = googlemaps.Client(key=GOOGLE_MAPS_API_KEY)\n",
    "\n",
    "locs = pd.DataFrame(denisa_df.Location.unique(), columns=[\"Location\"])\n",
    "\n",
    "# comment this out to avoid too many api calls\n",
    "locs[[\"Latitude\", \"Longitude\"]] = locs[\"Location\"].apply(lambda x: utils.get_coordinates_from_gmaps(x, gmaps_client))\n",
    "\n",
    "\n",
    "# denisa_df.Location.unique(), ashtyn_df.Location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read locations.yaml\n",
    "locs = utils.read_yaml(\"data/locations.yaml\")\n",
    "\n",
    "locs_df = pd.DataFrame([\n",
    "    {\n",
    "        \"DOI\": entry[\"DOI\"],\n",
    "        \"Latitude\": entry[\"coordinates\"][\"Latitude\"],\n",
    "        \"Longitude\": entry[\"coordinates\"][\"Longitude\"],\n",
    "        \"Location\": entry[\"location\"]\n",
    "    }\n",
    "    for entry in locs\n",
    "])\n",
    "\n",
    "# drop nans\n",
    "locs_df = locs_df.dropna()\n",
    "# read a list of dictionaries into a single dictionary, with the keys being the location names\n",
    "# locs = {k: v for d in locs for k, v in d.items()}\n",
    "\n",
    "# save dictionary to csv\n",
    "# locs = pd.DataFrame(locs)\n",
    "# locs.to_csv(\"data/locations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write locs to yaml, with nice formatting\n",
    "locs_list = []\n",
    "for _, row in doi_locs.iterrows():\n",
    "    locs_list.append({\n",
    "        'coordinates': {\n",
    "            'Latitude': row['Latitude'],\n",
    "            'Longitude': row['Longitude']\n",
    "        },\n",
    "        'location': row['Location'],\n",
    "        'DOI': row['DOI']\n",
    "    })\n",
    "\n",
    "utils.write_yaml(locs_list, \"data/locations.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot spatial disribution of studies\n",
    "locations = read_yaml(\"data/locations.yaml\")\n",
    "\n",
    "# create figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 20), subplot_kw={'projection': ccrs.PlateCarree()}, dpi=300)\n",
    "ax.set_extent([-180, 180, -40, 40], crs=ccrs.PlateCarree())\n",
    "\n",
    "# add features\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.OCEAN, alpha=0.3)\n",
    "ax.add_feature(cfeature.COASTLINE, edgecolor='lightgray')\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':', edgecolor='gray', alpha=0.2)\n",
    "\n",
    "# add locations with colors\n",
    "colors = sns.color_palette(\"hsv\", len(locations))\n",
    "for i, data in enumerate(locations):\n",
    "    coords = data[\"coordinates\"]\n",
    "    ax.plot(coords[\"Longitude\"], coords[\"Latitude\"], 'o', markeredgecolor='darkgrey', markersize=5, color=colors[i], transform=ccrs.PlateCarree(), label=data[\"location\"])\n",
    "\n",
    "# add legend\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -1.1), ncol=len(locations)//10, fontsize=6);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
