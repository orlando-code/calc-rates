```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(metafor) # need version 3.0 or higher (else 'regplot' function missing)
library(tidyverse)
library(tidyr)      # Explicitly load for drop_na function
library(dplyr)      # Explicitly load for pipe operator %>%
library(tidyselect) # Explicitly load for any_of function
library(MASS)
library(viridis)
library(patchwork)
library(magick)
library(ggsci)
library(ggpubr)
library(tidync)
library(lubridate)
library(rsvg)
library(svglite)
library(rmarkdown)
library(MuMIn)
library(here)
eval(metafor:::.MuMIn)
```

```{r ggplot settings}
# set general theme for figures
theme_cca <- function() {
  theme_classic(base_size = 12) +
    theme(
      panel.border = element_rect(colour = "black", fill = NA, linetype = 1),
      panel.background = element_rect(fill = "transparent"),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      axis.line = element_blank(),
      plot.title = element_text(face = "italic"),
      axis.text = element_text(colour = "black"),
      axis.ticks = element_line(colour = "black"),
      legend.position = c(0.1, 0.925),
      legend.text.align = 0,
      legend.background = element_blank(),
      legend.spacing = unit(0, "lines"),
      legend.key = element_blank(),
      legend.spacing.y = unit(0.25, "cm"),
      legend.title = element_blank()
    )
}

colour.scheme <- c("black",
  pal_npg(palette = c("nrc"), alpha = 1)(10)[4],
  pal_npg(palette = c("nrc"), alpha = 0.6)(10)[10],
  pal_npg(palette = c("nrc"), alpha = 0.6)(10)[1]
)

# ensure output directory present in same directory as script (for saving figures)
dir.create("output", showWarnings = FALSE)
```

```{r Helper functions}

# calculate the cooks distance threshold via 2âˆš((k+1)/(n - k - 1))
threshold <- function(data, mods_formula) {
  # extract the formula term count from the model used in run_meta_analysis
  k <- length(all.vars(mods_formula)) - 1 # k number of parameters in model (doesn't include the intercept removal term)
  n <- nrow(data)
  return(2 * sqrt((k + 1) / (n - k - 1))) # reproducible numerical replacement of eyeballing graph
}


filter_taxonomically <- function(indata, filter_variable, variable_value) {
  if (!is.null(variable_value)) {
    # Use get() to dynamically access the column name
    filtered_data <- indata %>%
      filter(!!sym(filter_variable) == variable_value)
    drops_count <- nrow(indata) - nrow(filtered_data)
    print(paste("Filtered to", filter_variable, ":", variable_value))
  } else {
    filtered_data <- indata
    drops_count <- 0
  }

  return(list(
    data = filtered_data,
    drops_count = drops_count
  ))
}


subset_data <- function(data, investigation, yi, V, filter_functional_group = NULL, filter_family = NULL, filter_genus = NULL, filter_taxa = NULL) {
  writeLines(paste("\nSelecting data for", investigation, "investigation..."))

  n_samples <- nrow(data)
  # Filter by investigation
  filtered_data <- dplyr::filter(data, stringr::str_detect(treatment, investigation))
  # Set necessary columns based on investigation type
  necessary_cols <- c(yi, V, "family", "genus", "taxa", "original_doi")
  if (investigation == "t_in") {
    necessary_cols <- c(necessary_cols, "delta_t", "t_in")
  } else if (investigation == "phtot") {
    necessary_cols <- c(necessary_cols, "delta_ph", "phtot", "t_in")
  }

  # Filter out rows with NAs in necessary columns
  filtered_data <- filtered_data %>%
    drop_na(any_of(necessary_cols))
  drops_nan <- nrow(data %>% filter(str_detect(treatment, investigation))) - nrow(filtered_data)
  
  # Apply taxonomic filters
  filters <- list(
    functional_group = filter_functional_group,
    family = filter_family,
    genus = filter_genus,
    taxa = filter_taxa
  )
  
  drops_count <- list()
  # Apply each filter if provided
  for (filter_name in names(filters)) {
    if (!is.null(filters[[filter_name]])) {
      result <- filter_taxonomically(filtered_data, filter_name, filters[[filter_name]])
      filtered_data <- result$data
      drops_count[[filter_name]] <- result$drops_count
    }
  }
  
  # Print summary
  print(paste("Total samples in input data:", n_samples))
  print(paste("Total samples of relevant investigation:", nrow(data %>% filter(str_detect(treatment, investigation)))))
  print(paste("Dropped due to NaN values:", drops_nan))
  
  for (filter_name in names(drops_count)) {
    print(paste("Dropped due to", filter_name, "filter:", drops_count[[filter_name]]))
  }
  
  print(paste("Final sample count:", nrow(filtered_data), 
              "(", n_samples - nrow(filtered_data), "total rows dropped )"))
  
  # Add an ID column
  filtered_data <- filtered_data %>% mutate(ID = seq_len(nrow(filtered_data)))
  return(filtered_data)
}
```


```{r Model results}
### save graphs to file
save_figures <- function(model, yi, data, mods_formula, save_dir = "output/", variable, run_id) {
  save_dir <- paste0(save_dir, variable, "/")
  if (!dir.exists(save_dir)) {
    dir.create(save_dir, recursive = TRUE, showWarnings = FALSE)
  }
  # # influence # Takes a really long time
  # influence_fp <- paste0(save_dir, variable, run_id, "influence.svg")
  # print(influence_fp)
  # svg(file = influence_fp, width = 10, height = 10)
  # plot(influence(model), main = paste(variable, "\n", as.character(mods_formula)))
  # dev.off()

  print(paste(yi))
  if (str_detect(yi, "raw")) {
    effect_type <- "% change in calcification rate"
  } else {
    effect_type <- "Hedges' g"
  }
  
  # forest
  forest_fp <- paste0(save_dir, gsub(" ", "", sprintf("forest_%s.svg", run_id)))
  svg(file = paste0(forest_fp), width = 10, height = max(30, length(unique(data$original_doi)) * .01))
  print(paste0("Saving forest plot to ", forest_fp))

  forest(model, addpred = TRUE, header = TRUE,
    ilab = paste(data$original_doi),
    main = paste(as.character(mods_formula)),
    xlab = effect_type,
    refline = NA  # temporarily disable the reference line
  )
  # add the reference line manually on top (otherwise gets buried behind)
  abline(v = 0, lty = "dashed", col = "red", lwd = 1.5)
  dev.off()

  # funnel
  funnel_fp <- paste0(save_dir, gsub(" ", "", sprintf("funnel_%s.svg", run_id)))
  svg(file = paste0(funnel_fp), width = 10, height = 10)
  print(paste0("Saving funnel plot to ", funnel_fp))
  funnel(model,
         main = paste(variable, "\n", as.character(mods_formula)),
         shade = c("white", "gray55", "gray75"),
         yaxs = "i", xaxs = "i",
         legend = TRUE, back = "gray90", hlines = NULL,
         xlab = effect_type,
         #  yaxis = "seinv",
         level = c(.1, .05, .01),
         las = 1, digits = list(1L, 3))
  dev.off()

  # bubble
  bubble_fp <- paste0(save_dir, gsub(" ", "", sprintf("bubble_%s.svg", run_id)))
  svg(file = paste0(bubble_fp), width = 8, height = 8)
  print(paste0("Saving bubble plot to ", bubble_fp))

  # Select the appropriate mod variable based on the investigation type
  mod_var <- if (variable == "t_in") "delta_t" else if (variable == "phtot") "delta_ph" else "delta_t"
  xlab_text <- if (variable == "t_in") {
    expression(paste("\U0394", "Temperature", " [", degree, "C]"))
  } else if (variable == "phtot") {
    expression(paste("\U0394", "pH")[T])
  } else {
    "Variable"
  }
  # set y-axis limits to +- 500 if effect size is raw, else +- 10
  if (str_detect(yi, "raw")) {
    ylim <- c(-500, 500)
  } else {
    ylim <- c(-10, 10)
  }

  regplot.rma(model, mod = mod_var, refline = 0,
    ylab = effect_type,
    xlab = xlab_text,
    main = bquote(.(as.character(mods_formula))),
    fig = TRUE,
    ylim = ylim
  )
  # set y axis limits
  dev.off()
}

print_model_summary <- function(model, variable, run_id, save_dir = "output/") {

  save_fp <- paste0(save_dir, variable, "/", run_id, "_", "model_summary.txt")
  # print model summary to console and save to file
  summary_obj <- summary(model)
  prediction_obj <- predict(model, digits = 5)

  # Create a connection to a text file
  file_conn <- file(save_fp, "w")

  options(width = 1000)  # Set width to a very large value

  # Write model summary and prediction to file with fewer line breaks
  writeLines("MODEL SUMMARY\n=============", file_conn)
  capture.output(print(summary_obj), file = file_conn, append = TRUE)
  writeLines("\n\nMODEL PREDICTION\n===============", file_conn)
  capture.output(print(prediction_obj), file = file_conn, append = TRUE)
  close(file_conn)
}
```

```{r Meta-analysis pipeline}
run_meta_analysis <- function(data, yi, V, mods_formula, threshold_val = NULL, parallel_opts = list(type = "multicore", ncpus = 8)) {
  # Eliminates anomalies based on Cook's distance, then runs a random-effects multi-level model.
  model <- rma.mv(yi = data[[yi]],
    V = data[[V]],
    data = data,
    method = "REML",
    mods = mods_formula,
    test = "z",
    random = list(~ 1 | (ID / original_doi)) # IDs are nested within original_doi
  )

  # if threshold in argument is NULL, compute
  if (is.null(threshold_val)) {
    threshold_val <- threshold(data, mods_formula)
  }
  cat(sprintf("Cook's distance threshold: %.2f\n", threshold_val))

  # calculate Cook's distance
  cooks_dist <- cooks.distance.rma.mv(
    model,
    progbar = TRUE,
    reestimate = TRUE,
    parallel = parallel_opts$type,
    ncpus = parallel_opts$ncpus,
    cl = NULL
  )
  # plot Cook's distances
  plot(cooks_dist, type = "o", pch = 19,
       xlab = "ID", ylab = "Cook's Distance (logarithmic scale)", xaxt = "n",
      log = "y",
       )
  # plot a horizontal line at the threshold value
  abline(h = threshold_val, col = "red", lty = 5)

  axis(side = 1, at = seq_along(cooks_dist),
       labels = as.numeric(names(cooks_dist)))


  # determine outliers
  outliers <- cooks_dist %>%
    as_tibble() %>%
    # mutate(ID = seq_len(nrow(data))) %>%
    filter(value > threshold_val)

  # remove outliers if any were found
  cleaned_data <- data
  # print(cleaned_data)
  print(data[-c(outliers$ID), ])

  if (nrow(outliers) > 0) {
    # Remove rows identified as outliers based on Cook's distance
    cleaned_data <- data[-c(outliers$ID), ]
    cat(sprintf("Removed %d outlier(s) out of %d samples\n", nrow(outliers), nrow(data)))
  } else {
    cat("No outliers detected\n")
  }

  # print(cleaned_data)

  # try to re-run model with cleaned data. if nlminb optimizer fails, stop execution
  final_model <- tryCatch({
    rma.mv(yi = cleaned_data[[yi]],
      V = cleaned_data[[V]],
      data = cleaned_data,
      method = "REML",
      mods = mods_formula,
      test = "z",
      random = list(~ 1 | (original_doi/ID))
    )
  }, error = function(e) {
    stop("Model convergence failed: ", e$message)
  })

  return(list(
    model = final_model,
    data = cleaned_data,
    outliers = outliers,
    cooks_dist = cooks_dist
  ))
}

meta_analysis_end_to_end <- function(data, variable, yi, V, mods_formula, run_id,
                                     filter_functional_group = NULL,
                                     filter_family = NULL, filter_taxa = NULL,
                                     filter_genus = NULL, threshold_val = NULL,
                                     save_dir = "output/",
                                     parallel_opts = list(type = "multicore", ncpus = 16)) {
  # run meta-analysis for specified formula, treatment variable, and taxa/genus filters
  # automatically saves forest and bubble plots to output directory
  subset <- subset_data(data, variable, yi, V, filter_functional_group = filter_functional_group, filter_family = filter_family, filter_taxa = filter_taxa, filter_genus = filter_genus)
  # run meta-analysis
  # Try to run meta-analysis and handle any errors
  results <- tryCatch({
    run_meta_analysis(subset, yi, V, mods_formula, threshold_val, parallel_opts)
  }, error = function(e) {
    cat(sprintf("\nERROR: Meta-analysis failed for %s with error: %s\n", run_id, e$message))
    return(NULL)
  })

  # If results is NULL (meaning an error occurred), return early
  if (is.null(results)) {
    cat(sprintf("\nSkipping plot generation for %s due to failed meta-analysis\n", run_id))
    return(NULL)
  }

  # extract model and data
  model <- results$model
  data <- results$data
  # Create a clean run_id by only including non-null filters
  filters <- c()
  if (!is.null(filter_functional_group)) filters <- c(filters, filter_functional_group)
  if (!is.null(filter_family)) filters <- c(filters, filter_family)
  if (!is.null(filter_taxa)) filters <- c(filters, filter_taxa)
  if (!is.null(filter_genus)) filters <- c(filters, filter_genus)

  # If we have filters, append them to run_id
  if (length(filters) > 0) {
    run_id <- paste0(run_id, "_", paste(filters, collapse = "_"))
  } else {
    run_id <- paste0(run_id, "_all_data")
  }
  # print(paste(yi))
  # save plots to file
  save_figures(model, yi, data, mods_formula, save_dir, variable, run_id)
  # save model summary to file
  print_model_summary(model, variable, run_id, save_dir)

  return (list(
    model = model,
    data = data,
    run_id = run_id
    ))
}
```

```{r Running: all data, naive model}
# ALL DATA PLOTS
# Set the working directory to the file's location for consistent data loading
all_data <- read.csv(here("data/tmp/effect_sizes.csv"))
# all_data <- read.csv(here("data/tmp/results_phtot.csv"))

# order the data by increasing hedges g
# all_data <- all_data[order(all_data$hedges_g), ]

# select first 50 rows for debugging
all_data <- all_data[0:100, ]

# remove rows for which effect_size_raw is > 500
# all_data <- all_data %>% filter(effect_size_raw < 500)

# ph_mods_formula <- ~ delta_ph + factor(family) - 1
# results <- meta_analysis_end_to_end(all_data, "phtot", ph_mods_formula, "phtot_naive")

ph_mods_formula <- ~ delta_ph + temp + factor(family) - 1
temp_mods_formula <- ~ delta_t + phtot + factor(family) - 1
# results <- meta_analysis_end_to_end(all_data, "phtot", "effect_size_raw", "effect_var_raw", mods_formula=ph_mods_formula, run_id="ph_naive_raw")
results <- meta_analysis_end_to_end(all_data, "temp", "effect_size_raw", "effect_var_raw", mods_formula=temp_mods_formula, run_id="temp_naive_raw")
# results <- meta_analysis_end_to_end(all_data, "phtot", "hedges_g", "hedges_g_var", mods_formula=temp_mods_formula, run_id="temp_naive")

```

```{r}
run_meta <- function(data, yi, V, mods_formula, threshold_val = NULL, parallel_opts = list(type = "multicore", ncpus = 16)) {
  
  model <- rma.mv(yi = data[[yi]],
    V = data[[V]],
    data = data,
    method = "REML",
    mods = mods_formula,
    test = "z",
    random = list(~ 1 | (ID / original_doi)) # IDs are nested within original_doi
  )
  # if threshold in argument is NULL, compute
  if (is.null(threshold_val)) {
    threshold_val <- threshold(data, mods_formula)
  }
  cat(sprintf("Cook's distance threshold: %.2f\n", threshold_val))
  # calculate Cook's distance
  cooks_dist <- cooks.distance.rma.mv(
    model,
    progbar = TRUE,
    reestimate = TRUE,
    # parallel = "multicore",
    # ncpus = 16,
    parallel = parallel_opts$type,
    ncpus = parallel_opts$ncpus,
    cl = NULL
  )
  print(cooks_dist)
  plot(cooks_dist, type = "o", pch = 19,
    xlab = "ID", ylab = "Cook's Distance (logarithmic scale)", xaxt = "n",
    # log = "y"
  )
  # plot a horizontal line at the threshold value
  abline(h = threshold_val, col = "red", lty = 5)

  axis(side = 1, at = seq_along(cooks_dist),
       labels = as.numeric(names(cooks_dist)))

  return(list(model=model, cooks_dist=cooks_dist))
}

all_data <- read.csv(here("data/tmp/effect_sizes.csv"))
all_data <- all_data[1:20, ]
# assign ID column
all_data <- all_data %>% mutate(ID = seq_len(nrow(all_data)))
subset <- subset_data(all_data, "phtot", "effect_size", "effect_var", filter_functional_group = NULL, filter_family = NULL, filter_genus = NULL, filter_taxa = NULL)
# run meta model with yi as effect_size and V as effect_var columns
temp_mods_formula <- ~ delta_ph + factor(family) - 1
out <- run_meta(subset, "effect_size", "effect_var", temp_mods_formula)


```
```{r}
  if (str_detect("effect_size", "raw")) {
    effect_type <- "% change in calcification rate"
  } else {
    effect_type <- "Hedges' g"
  }

  print(paste("Effect type:", effect_type))
```


```{r}

# subset <- subset_data(all_data, "temp", "effect_size", "effect_var", filter_functional_group = NULL, filter_family = NULL, filter_genus = NULL, filter_taxa = NULL)

# model <- rma.mv(yi = subset[["effect_size"]],
#   V = subset[["effect_var"]],
#   data = subset,
#   method = "REML",
#   mods = temp_mods_formula,
#   test = "z",
#   random = list(~ 1 | (ID / original_doi)) # IDs are nested within original_doi
# )
# threshold_val <- threshold(subset, temp_mods_formula)

# cooks_dist <- cooks.distance.rma.mv(
#   model,
#   progbar = TRUE,
#   # reestimate = TRUE,
#   parallel = "multicore",
#   ncpus = 16,
#   cl = NULL
# )
# model <- rma.mv(yi = all_data[['effect_size']],
#   V = all_data[['effect_var']],
#   data = all_data,
#   method = "REML",
#   mods = temp_mods_formula,
#   test = "z",
#   random = list(~ 1 | (ID / original_doi)) # IDs are nested within original_doi
# )


```
```{r MuMIn model investigation}
### DETERMINING THE BEST MODEL
all_data <- read.csv(here("data/tmp/results.csv"))

# select first 50 rows for debugging
# Note: using 0:50 will include row 0 which doesn't exist in R (indexing starts at 1)
# all_data <- all_data[1:500, ]
# filter data from the start to ensure model is fit on same data each time
# this is handled in functions but best to be sure
cols_to_include <- c("hedges_g", "hedges_g_var", "delta_ph", "phtot",
                     "delta_t", "t_in", "functional_group", "family",
                     "original_doi")

# select these columns in all_data
model_data <- all_data[, cols_to_include]

# # filter for the phtot treatment
model_data <- model_data %>% drop_na()
# create ID column
model_data <- model_data %>% mutate(ID = seq_len(nrow(model_data)))

# check for nans
cat("NUMBER OF NAN VALUES:", sum(is.na(model_data)), "\n")
# set model to fail if any nan values
options(na.action = "na.fail")

# all subsets regression via dredge
full_model <- rma.mv(yi = hedges_g,
                     V = hedges_g_var,
                     mods = ~ delta_ph + phtot + delta_t + t_in + factor(family) - 1,
                     random = ~ 1 | (original_doi / ID),
                     data = model_data,
                     method = "ML"
                     )
model_selection <- dredge(full_model, trace = 2)

# Get subset of models within 2 AICc points of the best model
subset(model_selection, delta <= 2, recalc.weights = FALSE)
# Extract the best model and refit using REML instead of ML
best_model <- get.models(model_selection, subset = 1, method = "REML")[[1]]
# Display the formula used in the best model
best_model$formula.mods

```

```{r Future predictions}


```

```{r}
# FAMILY PLOTS

# for each unique family in all_data, run the meta-analysis and save the plots with a distinct run_id
unique_families <- unique(all_data$family)

phtot_family_formula <- ~ delta_ph + phtot + t_in - 1
t_in_family_formula <- ~ delta_t + t_in - 1

ph_run_id <- "phtot_family"
t_in_run_id <- "t_in_family"

for (family in unique_families) {
  # print family run message and current index of family
  cat(sprintf(
              "\nRunning meta-analysis for family: %s (%d/%d)\n",
              family, which(unique_families == family), length(unique_families)))
  results <- meta_analysis_end_to_end(all_data, "phtot", phtot_family_formula, ph_run_id,
                                      filter_family = family, save_dir = "output/families/")

  results <- meta_analysis_end_to_end(all_data, "t_in", t_in_family_formula, t_in_run_id,
                                      filter_family = family, save_dir = "output/families/")
}
```

```{r}
# FUNCTIONAL GROUP PLOTS

functional_groups <- unique(all_data$functional_group)

func_group_phtot_formula <- ~ delta_ph + t_in + factor(family) - 1
func_group_t_in_formula <- ~ delta_t + t_in + factor(family) - 1

ph_run_id <- "phtot_fg"
t_in_run_id <- "t_in_fg"

for (func_group in functional_groups) {
  # print family run message and current index of family
  cat(sprintf(
              "\nRunning meta-analysis for functional group: %s (%d/%d)\n",
              func_group, which(functional_groups == func_group), length(functional_groups)))

  ph_run_id <- paste0("phtot_", func_group)
  results <- meta_analysis_end_to_end(all_data, "phtot", func_group_phtot_formula, ph_run_id, 
                                      filter_functional_group = func_group, save_dir = "output/func_groups/")

  t_in_run_id <- paste0("t_in_", func_group)
  results <- meta_analysis_end_to_end(all_data, "t_in", func_group_t_in_formula, t_in_run_id,
                                      filter_functional_group = func_group, save_dir = "output/func_groups/")
}
```


# Deprecated
# ```{r, fig.width = 6, fig.height = 8}

# # Overall plot of all studies assessing calcification in wrt temperature

# svg(file = 'output/t_in_overall_bubble_with_id_nested_algae_more.svg', width = 8, height = 8)

# regplot.rma(t_in_model, mod = "delta_t", refline = 0,
#   # xlim = c(-1,0.25),
#   ylim = c(-10, 5),
#   # predlim = c(-1,0.25),
#   ylab = "Hedges' g", xlab = expression(paste("\U0394", "Temperature", " [", degree, "C]")),
#   main = bquote(.(as.character(mods_formula)))
# )
# dev.off()
# ```

# ```{r}
# t_in_data_hedges <- read.csv(file="data/tmp/results_t_in.csv")
# n_samples <- nrow(t_in_data_hedges)
# # remove rows with nan values in necessary columns
# necessary_cols <- c("hedges_g", "hedges_g_var", "delta_t", "t_in", "genus", "taxa")
# # data cleaning
# t_in_data_hedges <- t_in_data_hedges %>% drop_na(necessary_cols)
# print(n_samples - nrow(t_in_data_hedges)) # print how many rows were dropped

# # filter to only include rows with 'coral' in taxa column
# t_in_data_hedges <- t_in_data_hedges %>% filter(str_detect(taxa, "Coral"))
# mods_formula <- ~ delta_t + t_in + factor(genus) - 1

# # run model for univariate analysis of temperature
# t_in_results <- run_meta_analysis(
#   data = t_in_data_hedges,
#   mods_formula = mods_formula # -ve 1 removes the model intercept
# )

# t_in_model <- t_in_results$model
# t_in_data_hedges <- t_in_results$data # cleaned data
# ```


# ```{r, fig.width = 6, fig.height = 8}

# # Overall plot of all studies assessing calcification in wrt temperature

# svg(file = 'output/t_in_overall_bubble_with_id_nested_algae_more.svg', width = 8, height = 8)

# regplot.rma(t_in_model, mod = "delta_t", refline = 0,
#   # xlim = c(-1,0.25),
#   ylim = c(-10, 5),
#   # predlim = c(-1,0.25),
#             ylab = "Hedges' g", xlab = expression(paste("\U0394", "Temperature", " [", degree, "C]")),
#                         main = bquote(.(as.character(mods_formula)))
# )
# dev.off()
# ```


# ```{r}
# phtot_data_hedges <- read.csv(file="data/tmp/results_phtot.csv")
# n_samples <- nrow(phtot_data_hedges)
# # remove rows with nan values in necessary columns
# necessary_cols <- c("hedges_g", "hedges_g_var", "delta_ph", "phtot", "genus")
# # data cleaning
# phtot_data_hedges <- phtot_data_hedges %>% drop_na(necessary_cols)
# print(n_samples - nrow(phtot_data_hedges)) # print how many rows were dropped

# phtot_data_hedges <- phtot_data_hedges %>% filter(str_detect(taxa, "Coral"))

# mods_formula = ~ delta_ph + phtot + t_in + factor(genus) - 1 # -ve 1 removes the model intercept
# # run model for univariate analysis of temperature
# phtot_results <- run_meta_analysis(
#   data = phtot_data_hedges,
#   mods_formula = mods_formula
# )

# phtot_model <- phtot_results$model
# phtot_hedges <- phtot_results$data # cleaned data
# ```


# ```{r, fig.width = 6, fig.height = 8}

# # Overall plot of all studies assessing calcification in wrt ph

# svg(file = 'output/phtot_overall_bubble_with_id_nested_coral_more.svg', width = 8, height = 8)

# regplot.rma(phtot_model, mod = "delta_ph", refline = 0, 
#   # xlim = c(-1,0.25),
#    ylim = c(-5,5), 
#    predlim = c(-1,0.25),
#             ylab = "Hedges' g", xlab = expression(paste("\U0394", "pH")[T]),
#             main = bquote(.(as.character(mods_formula)))
#       )
#       dev.off() 
# ```